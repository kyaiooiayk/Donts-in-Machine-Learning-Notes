{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to this python notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What? Data leakage and how to avoid it.\n",
    "\n",
    "Naive Data Preparation\n",
    "----------------------\n",
    "[1] Prepare Dataset\n",
    "[2] Split Data\n",
    "[3] Evaluate Models\n",
    "Correct procedure\n",
    "-----------------\n",
    "[1] Split Data.\n",
    "[2] Fit Data Preparation on Training Dataset\n",
    "[3] Apply Data Preparation to Train and Test Datasets\n",
    "[4] Evaluate Models\n",
    "\n",
    "Examples are as follows:\n",
    "[1] Train-Test Evaluation With Naive Data Preparation         -> WRONG\n",
    "[2] Train-Test Evaluation With Correct Data Preparation       -> RIGHT \n",
    "[3] Cross-Validation Evaluation With Naive Data Preparation   -> WRONG\n",
    "[4] Cross-Validation Evaluation With Correct Data Preparation -> RIGHT\n",
    "\n",
    "https://machinelearningmastery.com/data-preparation-without-data-leakage/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, std\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of a syntetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] Train-Test Evaluation With Naive Data Preparation -> WRONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naive approach to normalizing the data BEFORE splitting the data and evaluating the model\n",
    "Given we know that there was data leakage, we know that this estimate of model accuracy \n",
    "is wrong.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WRONG] Accuracy: 84.848\n"
     ]
    }
   ],
   "source": [
    "# [WRONG SERIAL STEP] standardize the dataset -> This is the MISTAKE\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) # fit the model\n",
    "\n",
    "# Fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('[WRONG] Accuracy: %.3f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] Train-Test Evaluation With Correct Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The correct approach to performing data preparation with a train-test split \n",
    "evaluation is to FIRST fit the data preparation on the training set, THEN \n",
    "apply the transform to the train and test sets.\n",
    "\n",
    "In this case, we can see that the estimate for the model is about 85.455 percent,\n",
    "which is more accurate than the estimate with data leakage in the previous section\n",
    "that achieved an accuracy of 84.848 percent. We would expect this to be an \n",
    "OPTIMISTIC estimate with data leakage\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CORRECT] Accuracy: 85.455\n"
     ]
    }
   ],
   "source": [
    "# [CORRECT SERIAL STEP] split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(X_train)\n",
    "# scale the training dataset\n",
    "X_train = scaler.transform(X_train)\n",
    "# scale the test dataset\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat) \n",
    "print('[CORRECT] Accuracy: %.3f' % (accuracy*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] Cross-Validation Evaluation With Naive Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, we can see that the model achieved an estimated accuracy of \n",
    "about 85.300 percent, which we know is incorrect given the data leakage \n",
    "allowed via the data preparation procedure.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WRONG] Accuracy: 85.300 (3.607)\n"
     ]
    }
   ],
   "source": [
    "# [WRONG serial step] standardize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model using cross-validation\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1) \n",
    "# Report performance using mean and standard deviation on all the folds\n",
    "print('[WRONG] Accuracy: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4] Cross-Validation Evaluation With Correct Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generally we expect for the data NOT leaked the performance is lower, due\n",
    "to the OPTIMISTIC prodiction provided done on leaked data. This is normal\n",
    "as leaking may or may not provide overfitting and therefore an improve in \n",
    "our score. NEVERTHELESS, the point here is that there is an effect and \n",
    "we should be aware of it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CORRECT] Accuracy: 85.433 (3.471)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "steps = list()\n",
    "steps.append(('scaler', MinMaxScaler()))\n",
    "steps.append(('model', LogisticRegression()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# define the evaluation procedure\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model using cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1) \n",
    "# Report performance using mean and standard deviation on all the folds\n",
    "print('[CORRECT] Accuracy: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
