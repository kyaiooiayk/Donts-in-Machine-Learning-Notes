{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What? Illustrating leakage in CV\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let’s consider a synthetic regression task with 100 samples and 1,000 features that are sampled independently \n",
    "from a Gaussian distribution. We also sample the response from a Gaussian distribution:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.RandomState(seed=0)\n",
    "X = rnd.normal(size=(100, 10000))\n",
    "y = rnd.normal(size=(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given the way we created the dataset, there is no relation between the data, X, and the target, y (they are \n",
    "independent), so it should not be possible to learn anything from this dataset. We will now do the following.\n",
    "HOWEVER if we are not careful ....\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaking info in CV - WRONG APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First, select the most informative of the 10 features using SelectPercentile feature selection, and then we \n",
    "evaluate a Ridge regressor using cross-validation:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_selected.shape: (100, 500)\n"
     ]
    }
   ],
   "source": [
    "select = SelectPercentile(score_func=f_regression, percentile=5).fit(X, y) \n",
    "X_selected = select.transform(X)\n",
    "print(\"X_selected.shape: {}\".format(X_selected.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy (cv only on ridge): 0.91\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-validation accuracy (cv only on ridge): {:.2f}\".format(\n",
    "np.mean(cross_val_score(Ridge(), X_selected, y, cv=5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What has gone wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The mean R2 computed by cross-validation is 0.91, indicating a very good model. This clearly cannot be right, as \n",
    "our data is entirely random. What happened here is that our feature selection picked out some features among the \n",
    "10,000 random features that are (by chance) very well correlated with the target. Because we fit the feature \n",
    "selection outside of the cross-validation, it could find features that are correlated both on the training and \n",
    "the test folds. The information we leaked from the test folds was very informative, leading to highly unrealistic \n",
    "results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No leakage - RIGHT APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy (pipeline): -0.25\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([(\"select\", SelectPercentile(score_func=f_regression,\n",
    "                                                 percentile=5)), (\"ridge\", Ridge())]) \n",
    "print(\"Cross-validation accuracy (pipeline): {:.2f}\".format(np.mean(cross_val_score(pipe, X, y, cv=5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why has this approach shown the correct result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This time, we get a negative R2 score, indicating a very poor model. Using the pipe‐ line, the feature selection \n",
    "is now inside the cross-validation loop. This means features can only be selected using the training folds of the \n",
    "data, not the test fold. The feature selection finds features that are correlated with the target on the training\n",
    "set, but because the data is entirely random, these features are not correlated with the target on the test set.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
